{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gR1F8Rh_X00M"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation,Dropout\n",
        "from tensorflow.keras.constraints import max_norm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()"
      ],
      "metadata": {
        "id": "se0VzbZCYBjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "# https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw\n",
        "\n",
        "\n",
        "# input layer\n",
        "model.add(Dense(78,  activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# hidden layer\n",
        "model.add(Dense(39, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# hidden layer\n",
        "model.add(Dense(19, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# output layer\n",
        "model.add(Dense(units=1,activation='sigmoid'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "Yp-G4BAUYOB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('parkinsons.csv')\n",
        "X = df.drop('name',axis=1).values\n",
        "y = df['name'].values\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=101)\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "XUJpVP_yYiGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del df['name']\n",
        "X = df.drop('status',axis=1).values\n",
        "y = df['status'].values"
      ],
      "metadata": {
        "id": "4D_MifJPhTnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "Zm4cXUPuhTxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=101)"
      ],
      "metadata": {
        "id": "RBIzA12QhT-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "QbXZkM4ihUJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()"
      ],
      "metadata": {
        "id": "fDjwU0xRh-eN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler.fit(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pO7D2mTph-rS",
        "outputId": "daf9a225-3007-4114-e342-bed16de5390f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MinMaxScaler()"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "X_g_2iDJh-50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation,Dropout"
      ],
      "metadata": {
        "id": "C3ToSYdQiT3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "# https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw\n",
        "\n",
        "model.add(Dense(units=30,activation='relu'))\n",
        "\n",
        "model.add(Dense(units=15,activation='relu'))\n",
        "\n",
        "\n",
        "model.add(Dense(units=1,activation='sigmoid'))\n",
        "\n",
        "# For a binary classification problem\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam')"
      ],
      "metadata": {
        "id": "zUulpr-biT5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://stats.stackexchange.com/questions/164876/tradeoff-batch-size-vs-number-of-iterations-to-train-a-neural-network\n",
        "# https://datascience.stackexchange.com/questions/18414/are-there-any-rules-for-choosing-the-size-of-a-mini-batch\n",
        "\n",
        "model.fit(x=X_train, \n",
        "          y=y_train, \n",
        "          epochs=600,\n",
        "          validation_data=(X_test, y_test), verbose=1\n",
        "          )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBaa6Qy8iT8Y",
        "outputId": "d0c0ea6b-255b-42cd-f927-913e7b317745"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/600\n",
            "5/5 [==============================] - 1s 49ms/step - loss: 0.5838 - val_loss: 0.5770\n",
            "Epoch 2/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5531 - val_loss: 0.5508\n",
            "Epoch 3/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5286 - val_loss: 0.5309\n",
            "Epoch 4/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.5131 - val_loss: 0.5151\n",
            "Epoch 5/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.5001 - val_loss: 0.5021\n",
            "Epoch 6/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4905 - val_loss: 0.4910\n",
            "Epoch 7/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.4842 - val_loss: 0.4817\n",
            "Epoch 8/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4763 - val_loss: 0.4724\n",
            "Epoch 9/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4698 - val_loss: 0.4636\n",
            "Epoch 10/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4632 - val_loss: 0.4541\n",
            "Epoch 11/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.4558 - val_loss: 0.4442\n",
            "Epoch 12/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4492 - val_loss: 0.4351\n",
            "Epoch 13/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.4415 - val_loss: 0.4258\n",
            "Epoch 14/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4344 - val_loss: 0.4165\n",
            "Epoch 15/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.4279 - val_loss: 0.4069\n",
            "Epoch 16/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4205 - val_loss: 0.3964\n",
            "Epoch 17/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4135 - val_loss: 0.3859\n",
            "Epoch 18/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.4081 - val_loss: 0.3744\n",
            "Epoch 19/600\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.4010 - val_loss: 0.3659\n",
            "Epoch 20/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3953 - val_loss: 0.3586\n",
            "Epoch 21/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3910 - val_loss: 0.3515\n",
            "Epoch 22/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3863 - val_loss: 0.3450\n",
            "Epoch 23/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3828 - val_loss: 0.3368\n",
            "Epoch 24/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3780 - val_loss: 0.3313\n",
            "Epoch 25/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3744 - val_loss: 0.3278\n",
            "Epoch 26/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3709 - val_loss: 0.3235\n",
            "Epoch 27/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3684 - val_loss: 0.3200\n",
            "Epoch 28/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3647 - val_loss: 0.3135\n",
            "Epoch 29/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3614 - val_loss: 0.3084\n",
            "Epoch 30/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3594 - val_loss: 0.3035\n",
            "Epoch 31/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3566 - val_loss: 0.3017\n",
            "Epoch 32/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3547 - val_loss: 0.3016\n",
            "Epoch 33/600\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.3529 - val_loss: 0.3005\n",
            "Epoch 34/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3499 - val_loss: 0.2961\n",
            "Epoch 35/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3467 - val_loss: 0.2905\n",
            "Epoch 36/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3449 - val_loss: 0.2856\n",
            "Epoch 37/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3438 - val_loss: 0.2848\n",
            "Epoch 38/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.3409 - val_loss: 0.2810\n",
            "Epoch 39/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3389 - val_loss: 0.2802\n",
            "Epoch 40/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3368 - val_loss: 0.2813\n",
            "Epoch 41/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3347 - val_loss: 0.2799\n",
            "Epoch 42/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3328 - val_loss: 0.2768\n",
            "Epoch 43/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3309 - val_loss: 0.2731\n",
            "Epoch 44/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3291 - val_loss: 0.2714\n",
            "Epoch 45/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3274 - val_loss: 0.2718\n",
            "Epoch 46/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3253 - val_loss: 0.2692\n",
            "Epoch 47/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3235 - val_loss: 0.2659\n",
            "Epoch 48/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3222 - val_loss: 0.2649\n",
            "Epoch 49/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3202 - val_loss: 0.2625\n",
            "Epoch 50/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3188 - val_loss: 0.2610\n",
            "Epoch 51/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3169 - val_loss: 0.2616\n",
            "Epoch 52/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3157 - val_loss: 0.2621\n",
            "Epoch 53/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3142 - val_loss: 0.2583\n",
            "Epoch 54/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3125 - val_loss: 0.2560\n",
            "Epoch 55/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3119 - val_loss: 0.2582\n",
            "Epoch 56/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3110 - val_loss: 0.2527\n",
            "Epoch 57/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3075 - val_loss: 0.2549\n",
            "Epoch 58/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.3063 - val_loss: 0.2534\n",
            "Epoch 59/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.3050 - val_loss: 0.2503\n",
            "Epoch 60/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.3039 - val_loss: 0.2507\n",
            "Epoch 61/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3022 - val_loss: 0.2480\n",
            "Epoch 62/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.3006 - val_loss: 0.2430\n",
            "Epoch 63/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3001 - val_loss: 0.2435\n",
            "Epoch 64/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.3003 - val_loss: 0.2403\n",
            "Epoch 65/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2979 - val_loss: 0.2448\n",
            "Epoch 66/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2970 - val_loss: 0.2474\n",
            "Epoch 67/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2947 - val_loss: 0.2441\n",
            "Epoch 68/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2936 - val_loss: 0.2399\n",
            "Epoch 69/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2932 - val_loss: 0.2374\n",
            "Epoch 70/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2906 - val_loss: 0.2411\n",
            "Epoch 71/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2893 - val_loss: 0.2421\n",
            "Epoch 72/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2886 - val_loss: 0.2430\n",
            "Epoch 73/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2878 - val_loss: 0.2369\n",
            "Epoch 74/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2868 - val_loss: 0.2333\n",
            "Epoch 75/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2848 - val_loss: 0.2327\n",
            "Epoch 76/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2834 - val_loss: 0.2322\n",
            "Epoch 77/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2839 - val_loss: 0.2363\n",
            "Epoch 78/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2819 - val_loss: 0.2291\n",
            "Epoch 79/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2802 - val_loss: 0.2277\n",
            "Epoch 80/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2789 - val_loss: 0.2305\n",
            "Epoch 81/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2781 - val_loss: 0.2328\n",
            "Epoch 82/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2770 - val_loss: 0.2293\n",
            "Epoch 83/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2755 - val_loss: 0.2271\n",
            "Epoch 84/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2752 - val_loss: 0.2249\n",
            "Epoch 85/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2742 - val_loss: 0.2278\n",
            "Epoch 86/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2727 - val_loss: 0.2275\n",
            "Epoch 87/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2713 - val_loss: 0.2249\n",
            "Epoch 88/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2715 - val_loss: 0.2210\n",
            "Epoch 89/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2697 - val_loss: 0.2212\n",
            "Epoch 90/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2684 - val_loss: 0.2224\n",
            "Epoch 91/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2675 - val_loss: 0.2214\n",
            "Epoch 92/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2671 - val_loss: 0.2172\n",
            "Epoch 93/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2666 - val_loss: 0.2208\n",
            "Epoch 94/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.2643 - val_loss: 0.2224\n",
            "Epoch 95/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2649 - val_loss: 0.2253\n",
            "Epoch 96/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2638 - val_loss: 0.2250\n",
            "Epoch 97/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2618 - val_loss: 0.2161\n",
            "Epoch 98/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2604 - val_loss: 0.2123\n",
            "Epoch 99/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2602 - val_loss: 0.2134\n",
            "Epoch 100/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2594 - val_loss: 0.2143\n",
            "Epoch 101/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2581 - val_loss: 0.2166\n",
            "Epoch 102/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2566 - val_loss: 0.2142\n",
            "Epoch 103/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2557 - val_loss: 0.2126\n",
            "Epoch 104/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.2553 - val_loss: 0.2093\n",
            "Epoch 105/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2542 - val_loss: 0.2056\n",
            "Epoch 106/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2536 - val_loss: 0.2063\n",
            "Epoch 107/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.2523 - val_loss: 0.2094\n",
            "Epoch 108/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2520 - val_loss: 0.2227\n",
            "Epoch 109/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2519 - val_loss: 0.2193\n",
            "Epoch 110/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2498 - val_loss: 0.2054\n",
            "Epoch 111/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2482 - val_loss: 0.2019\n",
            "Epoch 112/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2476 - val_loss: 0.2021\n",
            "Epoch 113/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2467 - val_loss: 0.2058\n",
            "Epoch 114/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2463 - val_loss: 0.2034\n",
            "Epoch 115/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2448 - val_loss: 0.2110\n",
            "Epoch 116/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.2447 - val_loss: 0.2159\n",
            "Epoch 117/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2436 - val_loss: 0.2097\n",
            "Epoch 118/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2431 - val_loss: 0.2022\n",
            "Epoch 119/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2411 - val_loss: 0.2012\n",
            "Epoch 120/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2394 - val_loss: 0.2033\n",
            "Epoch 121/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2386 - val_loss: 0.2048\n",
            "Epoch 122/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2374 - val_loss: 0.2016\n",
            "Epoch 123/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2367 - val_loss: 0.1983\n",
            "Epoch 124/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2353 - val_loss: 0.2003\n",
            "Epoch 125/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2352 - val_loss: 0.2062\n",
            "Epoch 126/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2338 - val_loss: 0.2022\n",
            "Epoch 127/600\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.2333 - val_loss: 0.1966\n",
            "Epoch 128/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2315 - val_loss: 0.1941\n",
            "Epoch 129/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2313 - val_loss: 0.1921\n",
            "Epoch 130/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2308 - val_loss: 0.1940\n",
            "Epoch 131/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2282 - val_loss: 0.1914\n",
            "Epoch 132/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2278 - val_loss: 0.1910\n",
            "Epoch 133/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2264 - val_loss: 0.1937\n",
            "Epoch 134/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2253 - val_loss: 0.1965\n",
            "Epoch 135/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2265 - val_loss: 0.2047\n",
            "Epoch 136/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2242 - val_loss: 0.1952\n",
            "Epoch 137/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2230 - val_loss: 0.1876\n",
            "Epoch 138/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2249 - val_loss: 0.1929\n",
            "Epoch 139/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2203 - val_loss: 0.1890\n",
            "Epoch 140/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2198 - val_loss: 0.1864\n",
            "Epoch 141/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2188 - val_loss: 0.1870\n",
            "Epoch 142/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2168 - val_loss: 0.1928\n",
            "Epoch 143/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2184 - val_loss: 0.1965\n",
            "Epoch 144/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.2155 - val_loss: 0.1902\n",
            "Epoch 145/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2138 - val_loss: 0.1849\n",
            "Epoch 146/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2136 - val_loss: 0.1832\n",
            "Epoch 147/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2124 - val_loss: 0.1833\n",
            "Epoch 148/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2130 - val_loss: 0.1862\n",
            "Epoch 149/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2102 - val_loss: 0.1852\n",
            "Epoch 150/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2092 - val_loss: 0.1831\n",
            "Epoch 151/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2092 - val_loss: 0.1832\n",
            "Epoch 152/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2072 - val_loss: 0.1834\n",
            "Epoch 153/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2084 - val_loss: 0.1784\n",
            "Epoch 154/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2058 - val_loss: 0.1811\n",
            "Epoch 155/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.2041 - val_loss: 0.1832\n",
            "Epoch 156/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2044 - val_loss: 0.1860\n",
            "Epoch 157/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2053 - val_loss: 0.1847\n",
            "Epoch 158/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.2020 - val_loss: 0.1745\n",
            "Epoch 159/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2013 - val_loss: 0.1730\n",
            "Epoch 160/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2003 - val_loss: 0.1801\n",
            "Epoch 161/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.2003 - val_loss: 0.1856\n",
            "Epoch 162/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1977 - val_loss: 0.1823\n",
            "Epoch 163/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1972 - val_loss: 0.1764\n",
            "Epoch 164/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1964 - val_loss: 0.1738\n",
            "Epoch 165/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1954 - val_loss: 0.1815\n",
            "Epoch 166/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1946 - val_loss: 0.1757\n",
            "Epoch 167/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1922 - val_loss: 0.1734\n",
            "Epoch 168/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1919 - val_loss: 0.1751\n",
            "Epoch 169/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1909 - val_loss: 0.1733\n",
            "Epoch 170/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1899 - val_loss: 0.1732\n",
            "Epoch 171/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1882 - val_loss: 0.1749\n",
            "Epoch 172/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1883 - val_loss: 0.1762\n",
            "Epoch 173/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1871 - val_loss: 0.1729\n",
            "Epoch 174/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1857 - val_loss: 0.1698\n",
            "Epoch 175/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1856 - val_loss: 0.1719\n",
            "Epoch 176/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1840 - val_loss: 0.1775\n",
            "Epoch 177/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1838 - val_loss: 0.1727\n",
            "Epoch 178/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1816 - val_loss: 0.1704\n",
            "Epoch 179/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1814 - val_loss: 0.1713\n",
            "Epoch 180/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1823 - val_loss: 0.1691\n",
            "Epoch 181/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1795 - val_loss: 0.1612\n",
            "Epoch 182/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1789 - val_loss: 0.1641\n",
            "Epoch 183/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1773 - val_loss: 0.1683\n",
            "Epoch 184/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1785 - val_loss: 0.1827\n",
            "Epoch 185/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1770 - val_loss: 0.1745\n",
            "Epoch 186/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1791 - val_loss: 0.1604\n",
            "Epoch 187/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1736 - val_loss: 0.1676\n",
            "Epoch 188/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1722 - val_loss: 0.1712\n",
            "Epoch 189/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1714 - val_loss: 0.1686\n",
            "Epoch 190/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1728 - val_loss: 0.1602\n",
            "Epoch 191/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1701 - val_loss: 0.1651\n",
            "Epoch 192/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1687 - val_loss: 0.1635\n",
            "Epoch 193/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1691 - val_loss: 0.1673\n",
            "Epoch 194/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1684 - val_loss: 0.1582\n",
            "Epoch 195/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1665 - val_loss: 0.1612\n",
            "Epoch 196/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1651 - val_loss: 0.1626\n",
            "Epoch 197/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1642 - val_loss: 0.1677\n",
            "Epoch 198/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1633 - val_loss: 0.1689\n",
            "Epoch 199/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1646 - val_loss: 0.1609\n",
            "Epoch 200/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1609 - val_loss: 0.1606\n",
            "Epoch 201/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1599 - val_loss: 0.1607\n",
            "Epoch 202/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1594 - val_loss: 0.1587\n",
            "Epoch 203/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1580 - val_loss: 0.1595\n",
            "Epoch 204/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1585 - val_loss: 0.1550\n",
            "Epoch 205/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1566 - val_loss: 0.1599\n",
            "Epoch 206/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1557 - val_loss: 0.1596\n",
            "Epoch 207/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1546 - val_loss: 0.1581\n",
            "Epoch 208/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1541 - val_loss: 0.1555\n",
            "Epoch 209/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1540 - val_loss: 0.1541\n",
            "Epoch 210/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1526 - val_loss: 0.1583\n",
            "Epoch 211/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1515 - val_loss: 0.1537\n",
            "Epoch 212/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1520 - val_loss: 0.1566\n",
            "Epoch 213/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1509 - val_loss: 0.1499\n",
            "Epoch 214/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1493 - val_loss: 0.1551\n",
            "Epoch 215/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1479 - val_loss: 0.1588\n",
            "Epoch 216/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1470 - val_loss: 0.1554\n",
            "Epoch 217/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1475 - val_loss: 0.1512\n",
            "Epoch 218/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1452 - val_loss: 0.1575\n",
            "Epoch 219/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1450 - val_loss: 0.1620\n",
            "Epoch 220/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1457 - val_loss: 0.1566\n",
            "Epoch 221/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1433 - val_loss: 0.1580\n",
            "Epoch 222/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1440 - val_loss: 0.1622\n",
            "Epoch 223/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1427 - val_loss: 0.1497\n",
            "Epoch 224/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1404 - val_loss: 0.1483\n",
            "Epoch 225/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1400 - val_loss: 0.1481\n",
            "Epoch 226/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1392 - val_loss: 0.1558\n",
            "Epoch 227/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1381 - val_loss: 0.1555\n",
            "Epoch 228/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1373 - val_loss: 0.1511\n",
            "Epoch 229/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1359 - val_loss: 0.1487\n",
            "Epoch 230/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.1358 - val_loss: 0.1464\n",
            "Epoch 231/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1353 - val_loss: 0.1481\n",
            "Epoch 232/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1356 - val_loss: 0.1564\n",
            "Epoch 233/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1340 - val_loss: 0.1517\n",
            "Epoch 234/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1347 - val_loss: 0.1389\n",
            "Epoch 235/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1335 - val_loss: 0.1428\n",
            "Epoch 236/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1322 - val_loss: 0.1450\n",
            "Epoch 237/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1302 - val_loss: 0.1454\n",
            "Epoch 238/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1298 - val_loss: 0.1540\n",
            "Epoch 239/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1291 - val_loss: 0.1519\n",
            "Epoch 240/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1280 - val_loss: 0.1471\n",
            "Epoch 241/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1279 - val_loss: 0.1392\n",
            "Epoch 242/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1276 - val_loss: 0.1445\n",
            "Epoch 243/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1258 - val_loss: 0.1458\n",
            "Epoch 244/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1261 - val_loss: 0.1435\n",
            "Epoch 245/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1245 - val_loss: 0.1466\n",
            "Epoch 246/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1256 - val_loss: 0.1514\n",
            "Epoch 247/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1222 - val_loss: 0.1412\n",
            "Epoch 248/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1227 - val_loss: 0.1374\n",
            "Epoch 249/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1227 - val_loss: 0.1361\n",
            "Epoch 250/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1223 - val_loss: 0.1499\n",
            "Epoch 251/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1207 - val_loss: 0.1481\n",
            "Epoch 252/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1198 - val_loss: 0.1527\n",
            "Epoch 253/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1194 - val_loss: 0.1469\n",
            "Epoch 254/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1181 - val_loss: 0.1340\n",
            "Epoch 255/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1180 - val_loss: 0.1345\n",
            "Epoch 256/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1166 - val_loss: 0.1372\n",
            "Epoch 257/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1159 - val_loss: 0.1425\n",
            "Epoch 258/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1153 - val_loss: 0.1461\n",
            "Epoch 259/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1141 - val_loss: 0.1464\n",
            "Epoch 260/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1135 - val_loss: 0.1481\n",
            "Epoch 261/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.1136 - val_loss: 0.1483\n",
            "Epoch 262/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.1126 - val_loss: 0.1449\n",
            "Epoch 263/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1132 - val_loss: 0.1337\n",
            "Epoch 264/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.1117 - val_loss: 0.1357\n",
            "Epoch 265/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1100 - val_loss: 0.1397\n",
            "Epoch 266/600\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.1092 - val_loss: 0.1451\n",
            "Epoch 267/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1086 - val_loss: 0.1487\n",
            "Epoch 268/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1090 - val_loss: 0.1430\n",
            "Epoch 269/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1075 - val_loss: 0.1445\n",
            "Epoch 270/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1066 - val_loss: 0.1434\n",
            "Epoch 271/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1063 - val_loss: 0.1360\n",
            "Epoch 272/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1070 - val_loss: 0.1378\n",
            "Epoch 273/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1049 - val_loss: 0.1355\n",
            "Epoch 274/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1045 - val_loss: 0.1357\n",
            "Epoch 275/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1031 - val_loss: 0.1347\n",
            "Epoch 276/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.1034 - val_loss: 0.1374\n",
            "Epoch 277/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1024 - val_loss: 0.1340\n",
            "Epoch 278/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1010 - val_loss: 0.1380\n",
            "Epoch 279/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1006 - val_loss: 0.1394\n",
            "Epoch 280/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.1005 - val_loss: 0.1369\n",
            "Epoch 281/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0996 - val_loss: 0.1381\n",
            "Epoch 282/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0985 - val_loss: 0.1386\n",
            "Epoch 283/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0989 - val_loss: 0.1447\n",
            "Epoch 284/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0998 - val_loss: 0.1462\n",
            "Epoch 285/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0972 - val_loss: 0.1301\n",
            "Epoch 286/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0963 - val_loss: 0.1247\n",
            "Epoch 287/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0962 - val_loss: 0.1261\n",
            "Epoch 288/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0951 - val_loss: 0.1327\n",
            "Epoch 289/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0945 - val_loss: 0.1405\n",
            "Epoch 290/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0944 - val_loss: 0.1381\n",
            "Epoch 291/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0931 - val_loss: 0.1373\n",
            "Epoch 292/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0926 - val_loss: 0.1352\n",
            "Epoch 293/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0921 - val_loss: 0.1279\n",
            "Epoch 294/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0915 - val_loss: 0.1290\n",
            "Epoch 295/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0920 - val_loss: 0.1378\n",
            "Epoch 296/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0911 - val_loss: 0.1314\n",
            "Epoch 297/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0919 - val_loss: 0.1263\n",
            "Epoch 298/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0892 - val_loss: 0.1343\n",
            "Epoch 299/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0886 - val_loss: 0.1423\n",
            "Epoch 300/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0889 - val_loss: 0.1388\n",
            "Epoch 301/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0874 - val_loss: 0.1270\n",
            "Epoch 302/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0871 - val_loss: 0.1264\n",
            "Epoch 303/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0868 - val_loss: 0.1271\n",
            "Epoch 304/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0858 - val_loss: 0.1306\n",
            "Epoch 305/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0871 - val_loss: 0.1345\n",
            "Epoch 306/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0881 - val_loss: 0.1197\n",
            "Epoch 307/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0865 - val_loss: 0.1355\n",
            "Epoch 308/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0837 - val_loss: 0.1342\n",
            "Epoch 309/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0837 - val_loss: 0.1323\n",
            "Epoch 310/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0824 - val_loss: 0.1335\n",
            "Epoch 311/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0826 - val_loss: 0.1287\n",
            "Epoch 312/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0820 - val_loss: 0.1286\n",
            "Epoch 313/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0817 - val_loss: 0.1302\n",
            "Epoch 314/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0804 - val_loss: 0.1379\n",
            "Epoch 315/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0803 - val_loss: 0.1361\n",
            "Epoch 316/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0796 - val_loss: 0.1322\n",
            "Epoch 317/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0798 - val_loss: 0.1253\n",
            "Epoch 318/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0787 - val_loss: 0.1295\n",
            "Epoch 319/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0787 - val_loss: 0.1245\n",
            "Epoch 320/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0780 - val_loss: 0.1330\n",
            "Epoch 321/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0774 - val_loss: 0.1289\n",
            "Epoch 322/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0766 - val_loss: 0.1290\n",
            "Epoch 323/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0758 - val_loss: 0.1259\n",
            "Epoch 324/600\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0760 - val_loss: 0.1204\n",
            "Epoch 325/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0766 - val_loss: 0.1301\n",
            "Epoch 326/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0751 - val_loss: 0.1240\n",
            "Epoch 327/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0742 - val_loss: 0.1143\n",
            "Epoch 328/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0768 - val_loss: 0.1271\n",
            "Epoch 329/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0731 - val_loss: 0.1266\n",
            "Epoch 330/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0727 - val_loss: 0.1274\n",
            "Epoch 331/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0718 - val_loss: 0.1290\n",
            "Epoch 332/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0714 - val_loss: 0.1250\n",
            "Epoch 333/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0716 - val_loss: 0.1216\n",
            "Epoch 334/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0706 - val_loss: 0.1320\n",
            "Epoch 335/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0704 - val_loss: 0.1315\n",
            "Epoch 336/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0696 - val_loss: 0.1233\n",
            "Epoch 337/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0688 - val_loss: 0.1186\n",
            "Epoch 338/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0701 - val_loss: 0.1158\n",
            "Epoch 339/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0710 - val_loss: 0.1304\n",
            "Epoch 340/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0689 - val_loss: 0.1269\n",
            "Epoch 341/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0686 - val_loss: 0.1149\n",
            "Epoch 342/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0678 - val_loss: 0.1148\n",
            "Epoch 343/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0673 - val_loss: 0.1221\n",
            "Epoch 344/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0659 - val_loss: 0.1307\n",
            "Epoch 345/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0688 - val_loss: 0.1384\n",
            "Epoch 346/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0672 - val_loss: 0.1164\n",
            "Epoch 347/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0658 - val_loss: 0.1168\n",
            "Epoch 348/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0654 - val_loss: 0.1220\n",
            "Epoch 349/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0642 - val_loss: 0.1256\n",
            "Epoch 350/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0645 - val_loss: 0.1267\n",
            "Epoch 351/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0632 - val_loss: 0.1183\n",
            "Epoch 352/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0630 - val_loss: 0.1187\n",
            "Epoch 353/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0626 - val_loss: 0.1209\n",
            "Epoch 354/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0633 - val_loss: 0.1227\n",
            "Epoch 355/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0619 - val_loss: 0.1244\n",
            "Epoch 356/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0618 - val_loss: 0.1277\n",
            "Epoch 357/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0610 - val_loss: 0.1189\n",
            "Epoch 358/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0604 - val_loss: 0.1154\n",
            "Epoch 359/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0607 - val_loss: 0.1180\n",
            "Epoch 360/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0605 - val_loss: 0.1180\n",
            "Epoch 361/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0589 - val_loss: 0.1303\n",
            "Epoch 362/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0604 - val_loss: 0.1434\n",
            "Epoch 363/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0600 - val_loss: 0.1338\n",
            "Epoch 364/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0582 - val_loss: 0.1232\n",
            "Epoch 365/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0577 - val_loss: 0.1139\n",
            "Epoch 366/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0583 - val_loss: 0.1151\n",
            "Epoch 367/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0570 - val_loss: 0.1161\n",
            "Epoch 368/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0566 - val_loss: 0.1191\n",
            "Epoch 369/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0568 - val_loss: 0.1265\n",
            "Epoch 370/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0563 - val_loss: 0.1207\n",
            "Epoch 371/600\n",
            "5/5 [==============================] - 0s 44ms/step - loss: 0.0556 - val_loss: 0.1211\n",
            "Epoch 372/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0562 - val_loss: 0.1254\n",
            "Epoch 373/600\n",
            "5/5 [==============================] - 0s 20ms/step - loss: 0.0547 - val_loss: 0.1193\n",
            "Epoch 374/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0545 - val_loss: 0.1158\n",
            "Epoch 375/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0549 - val_loss: 0.1170\n",
            "Epoch 376/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0542 - val_loss: 0.1347\n",
            "Epoch 377/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0549 - val_loss: 0.1324\n",
            "Epoch 378/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0534 - val_loss: 0.1187\n",
            "Epoch 379/600\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0540 - val_loss: 0.1102\n",
            "Epoch 380/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0529 - val_loss: 0.1190\n",
            "Epoch 381/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0521 - val_loss: 0.1297\n",
            "Epoch 382/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0523 - val_loss: 0.1238\n",
            "Epoch 383/600\n",
            "5/5 [==============================] - 0s 33ms/step - loss: 0.0522 - val_loss: 0.1162\n",
            "Epoch 384/600\n",
            "5/5 [==============================] - 0s 31ms/step - loss: 0.0526 - val_loss: 0.1243\n",
            "Epoch 385/600\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0511 - val_loss: 0.1136\n",
            "Epoch 386/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0514 - val_loss: 0.1141\n",
            "Epoch 387/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0499 - val_loss: 0.1275\n",
            "Epoch 388/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0509 - val_loss: 0.1401\n",
            "Epoch 389/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0504 - val_loss: 0.1271\n",
            "Epoch 390/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0488 - val_loss: 0.1144\n",
            "Epoch 391/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0495 - val_loss: 0.1125\n",
            "Epoch 392/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0495 - val_loss: 0.1202\n",
            "Epoch 393/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0486 - val_loss: 0.1277\n",
            "Epoch 394/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0479 - val_loss: 0.1284\n",
            "Epoch 395/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0479 - val_loss: 0.1246\n",
            "Epoch 396/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0475 - val_loss: 0.1156\n",
            "Epoch 397/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0481 - val_loss: 0.1148\n",
            "Epoch 398/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0471 - val_loss: 0.1266\n",
            "Epoch 399/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0477 - val_loss: 0.1296\n",
            "Epoch 400/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0469 - val_loss: 0.1216\n",
            "Epoch 401/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0459 - val_loss: 0.1190\n",
            "Epoch 402/600\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 0.0462 - val_loss: 0.1191\n",
            "Epoch 403/600\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 0.0459 - val_loss: 0.1217\n",
            "Epoch 404/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0468 - val_loss: 0.1147\n",
            "Epoch 405/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0463 - val_loss: 0.1361\n",
            "Epoch 406/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0465 - val_loss: 0.1305\n",
            "Epoch 407/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0444 - val_loss: 0.1112\n",
            "Epoch 408/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0450 - val_loss: 0.1178\n",
            "Epoch 409/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0441 - val_loss: 0.1287\n",
            "Epoch 410/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0441 - val_loss: 0.1284\n",
            "Epoch 411/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0437 - val_loss: 0.1206\n",
            "Epoch 412/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0443 - val_loss: 0.1112\n",
            "Epoch 413/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0429 - val_loss: 0.1183\n",
            "Epoch 414/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0425 - val_loss: 0.1250\n",
            "Epoch 415/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0424 - val_loss: 0.1215\n",
            "Epoch 416/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0422 - val_loss: 0.1261\n",
            "Epoch 417/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0421 - val_loss: 0.1244\n",
            "Epoch 418/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0421 - val_loss: 0.1150\n",
            "Epoch 419/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0423 - val_loss: 0.1212\n",
            "Epoch 420/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0410 - val_loss: 0.1254\n",
            "Epoch 421/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0409 - val_loss: 0.1243\n",
            "Epoch 422/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0409 - val_loss: 0.1138\n",
            "Epoch 423/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0406 - val_loss: 0.1135\n",
            "Epoch 424/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0425 - val_loss: 0.1078\n",
            "Epoch 425/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0403 - val_loss: 0.1238\n",
            "Epoch 426/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0395 - val_loss: 0.1284\n",
            "Epoch 427/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0397 - val_loss: 0.1256\n",
            "Epoch 428/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0391 - val_loss: 0.1284\n",
            "Epoch 429/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0391 - val_loss: 0.1231\n",
            "Epoch 430/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0387 - val_loss: 0.1234\n",
            "Epoch 431/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0387 - val_loss: 0.1211\n",
            "Epoch 432/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0383 - val_loss: 0.1277\n",
            "Epoch 433/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0381 - val_loss: 0.1243\n",
            "Epoch 434/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0379 - val_loss: 0.1210\n",
            "Epoch 435/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0375 - val_loss: 0.1244\n",
            "Epoch 436/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0376 - val_loss: 0.1221\n",
            "Epoch 437/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0373 - val_loss: 0.1235\n",
            "Epoch 438/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0370 - val_loss: 0.1214\n",
            "Epoch 439/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0368 - val_loss: 0.1202\n",
            "Epoch 440/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0365 - val_loss: 0.1195\n",
            "Epoch 441/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0364 - val_loss: 0.1217\n",
            "Epoch 442/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0360 - val_loss: 0.1130\n",
            "Epoch 443/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0359 - val_loss: 0.1105\n",
            "Epoch 444/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0363 - val_loss: 0.1181\n",
            "Epoch 445/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0355 - val_loss: 0.1179\n",
            "Epoch 446/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0353 - val_loss: 0.1177\n",
            "Epoch 447/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0351 - val_loss: 0.1138\n",
            "Epoch 448/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0350 - val_loss: 0.1138\n",
            "Epoch 449/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0347 - val_loss: 0.1243\n",
            "Epoch 450/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0347 - val_loss: 0.1339\n",
            "Epoch 451/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0357 - val_loss: 0.1231\n",
            "Epoch 452/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0339 - val_loss: 0.1203\n",
            "Epoch 453/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0339 - val_loss: 0.1146\n",
            "Epoch 454/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0337 - val_loss: 0.1177\n",
            "Epoch 455/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0336 - val_loss: 0.1137\n",
            "Epoch 456/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0332 - val_loss: 0.1218\n",
            "Epoch 457/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0333 - val_loss: 0.1225\n",
            "Epoch 458/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0332 - val_loss: 0.1168\n",
            "Epoch 459/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0327 - val_loss: 0.1208\n",
            "Epoch 460/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0324 - val_loss: 0.1169\n",
            "Epoch 461/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0323 - val_loss: 0.1133\n",
            "Epoch 462/600\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0326 - val_loss: 0.1169\n",
            "Epoch 463/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0320 - val_loss: 0.1119\n",
            "Epoch 464/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0319 - val_loss: 0.1182\n",
            "Epoch 465/600\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0316 - val_loss: 0.1225\n",
            "Epoch 466/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0315 - val_loss: 0.1188\n",
            "Epoch 467/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0317 - val_loss: 0.1266\n",
            "Epoch 468/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0312 - val_loss: 0.1198\n",
            "Epoch 469/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0309 - val_loss: 0.1136\n",
            "Epoch 470/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0309 - val_loss: 0.1067\n",
            "Epoch 471/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0310 - val_loss: 0.1095\n",
            "Epoch 472/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0304 - val_loss: 0.1169\n",
            "Epoch 473/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0304 - val_loss: 0.1153\n",
            "Epoch 474/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0302 - val_loss: 0.1196\n",
            "Epoch 475/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0300 - val_loss: 0.1172\n",
            "Epoch 476/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0300 - val_loss: 0.1202\n",
            "Epoch 477/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0304 - val_loss: 0.1107\n",
            "Epoch 478/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0296 - val_loss: 0.1181\n",
            "Epoch 479/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0292 - val_loss: 0.1208\n",
            "Epoch 480/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0291 - val_loss: 0.1168\n",
            "Epoch 481/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0294 - val_loss: 0.1080\n",
            "Epoch 482/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0299 - val_loss: 0.1085\n",
            "Epoch 483/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0288 - val_loss: 0.1275\n",
            "Epoch 484/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0285 - val_loss: 0.1272\n",
            "Epoch 485/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0282 - val_loss: 0.1175\n",
            "Epoch 486/600\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.0285 - val_loss: 0.1104\n",
            "Epoch 487/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0287 - val_loss: 0.1271\n",
            "Epoch 488/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0282 - val_loss: 0.1254\n",
            "Epoch 489/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0282 - val_loss: 0.1044\n",
            "Epoch 490/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0283 - val_loss: 0.1037\n",
            "Epoch 491/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0276 - val_loss: 0.1104\n",
            "Epoch 492/600\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0272 - val_loss: 0.1181\n",
            "Epoch 493/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0270 - val_loss: 0.1221\n",
            "Epoch 494/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0272 - val_loss: 0.1225\n",
            "Epoch 495/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0266 - val_loss: 0.1180\n",
            "Epoch 496/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0269 - val_loss: 0.1121\n",
            "Epoch 497/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0264 - val_loss: 0.1245\n",
            "Epoch 498/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0264 - val_loss: 0.1273\n",
            "Epoch 499/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0264 - val_loss: 0.1219\n",
            "Epoch 500/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0260 - val_loss: 0.1248\n",
            "Epoch 501/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0260 - val_loss: 0.1191\n",
            "Epoch 502/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0257 - val_loss: 0.1246\n",
            "Epoch 503/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0257 - val_loss: 0.1166\n",
            "Epoch 504/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0252 - val_loss: 0.1113\n",
            "Epoch 505/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0255 - val_loss: 0.1070\n",
            "Epoch 506/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0255 - val_loss: 0.1118\n",
            "Epoch 507/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0255 - val_loss: 0.1243\n",
            "Epoch 508/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0251 - val_loss: 0.1206\n",
            "Epoch 509/600\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0248 - val_loss: 0.1191\n",
            "Epoch 510/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0245 - val_loss: 0.1167\n",
            "Epoch 511/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0255 - val_loss: 0.1232\n",
            "Epoch 512/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0246 - val_loss: 0.1083\n",
            "Epoch 513/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0245 - val_loss: 0.1077\n",
            "Epoch 514/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0247 - val_loss: 0.1178\n",
            "Epoch 515/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0240 - val_loss: 0.1178\n",
            "Epoch 516/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0240 - val_loss: 0.1163\n",
            "Epoch 517/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0239 - val_loss: 0.1207\n",
            "Epoch 518/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0239 - val_loss: 0.1171\n",
            "Epoch 519/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0234 - val_loss: 0.1110\n",
            "Epoch 520/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0236 - val_loss: 0.1126\n",
            "Epoch 521/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0231 - val_loss: 0.1247\n",
            "Epoch 522/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0231 - val_loss: 0.1259\n",
            "Epoch 523/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0232 - val_loss: 0.1163\n",
            "Epoch 524/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0231 - val_loss: 0.1200\n",
            "Epoch 525/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0226 - val_loss: 0.1170\n",
            "Epoch 526/600\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0225 - val_loss: 0.1154\n",
            "Epoch 527/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0225 - val_loss: 0.1140\n",
            "Epoch 528/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0226 - val_loss: 0.1104\n",
            "Epoch 529/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0222 - val_loss: 0.1148\n",
            "Epoch 530/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0229 - val_loss: 0.1223\n",
            "Epoch 531/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0222 - val_loss: 0.1131\n",
            "Epoch 532/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0220 - val_loss: 0.1136\n",
            "Epoch 533/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0218 - val_loss: 0.1159\n",
            "Epoch 534/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0218 - val_loss: 0.1151\n",
            "Epoch 535/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0220 - val_loss: 0.1196\n",
            "Epoch 536/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0218 - val_loss: 0.1141\n",
            "Epoch 537/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0213 - val_loss: 0.1208\n",
            "Epoch 538/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0212 - val_loss: 0.1234\n",
            "Epoch 539/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0216 - val_loss: 0.1263\n",
            "Epoch 540/600\n",
            "5/5 [==============================] - 0s 14ms/step - loss: 0.0210 - val_loss: 0.1187\n",
            "Epoch 541/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0211 - val_loss: 0.1082\n",
            "Epoch 542/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0211 - val_loss: 0.1169\n",
            "Epoch 543/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0206 - val_loss: 0.1179\n",
            "Epoch 544/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0206 - val_loss: 0.1185\n",
            "Epoch 545/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0205 - val_loss: 0.1157\n",
            "Epoch 546/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0204 - val_loss: 0.1131\n",
            "Epoch 547/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0203 - val_loss: 0.1145\n",
            "Epoch 548/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0201 - val_loss: 0.1185\n",
            "Epoch 549/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0202 - val_loss: 0.1225\n",
            "Epoch 550/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0201 - val_loss: 0.1195\n",
            "Epoch 551/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0201 - val_loss: 0.1117\n",
            "Epoch 552/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0199 - val_loss: 0.1168\n",
            "Epoch 553/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0199 - val_loss: 0.1188\n",
            "Epoch 554/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0199 - val_loss: 0.1127\n",
            "Epoch 555/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0196 - val_loss: 0.1202\n",
            "Epoch 556/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0196 - val_loss: 0.1229\n",
            "Epoch 557/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0195 - val_loss: 0.1140\n",
            "Epoch 558/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0194 - val_loss: 0.1146\n",
            "Epoch 559/600\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 0.0191 - val_loss: 0.1108\n",
            "Epoch 560/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0194 - val_loss: 0.1104\n",
            "Epoch 561/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0190 - val_loss: 0.1141\n",
            "Epoch 562/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0188 - val_loss: 0.1196\n",
            "Epoch 563/600\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.0189 - val_loss: 0.1178\n",
            "Epoch 564/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0188 - val_loss: 0.1216\n",
            "Epoch 565/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0186 - val_loss: 0.1167\n",
            "Epoch 566/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0185 - val_loss: 0.1137\n",
            "Epoch 567/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0183 - val_loss: 0.1167\n",
            "Epoch 568/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0182 - val_loss: 0.1208\n",
            "Epoch 569/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0183 - val_loss: 0.1172\n",
            "Epoch 570/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0182 - val_loss: 0.1179\n",
            "Epoch 571/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0183 - val_loss: 0.1112\n",
            "Epoch 572/600\n",
            "5/5 [==============================] - 0s 16ms/step - loss: 0.0181 - val_loss: 0.1201\n",
            "Epoch 573/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0180 - val_loss: 0.1177\n",
            "Epoch 574/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0177 - val_loss: 0.1196\n",
            "Epoch 575/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0178 - val_loss: 0.1158\n",
            "Epoch 576/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0177 - val_loss: 0.1129\n",
            "Epoch 577/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0177 - val_loss: 0.1098\n",
            "Epoch 578/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0174 - val_loss: 0.1177\n",
            "Epoch 579/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.1202\n",
            "Epoch 580/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0175 - val_loss: 0.1165\n",
            "Epoch 581/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0174 - val_loss: 0.1055\n",
            "Epoch 582/600\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.0173 - val_loss: 0.1118\n",
            "Epoch 583/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0169 - val_loss: 0.1202\n",
            "Epoch 584/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0172 - val_loss: 0.1266\n",
            "Epoch 585/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0173 - val_loss: 0.1196\n",
            "Epoch 586/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0170 - val_loss: 0.1050\n",
            "Epoch 587/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0174 - val_loss: 0.1067\n",
            "Epoch 588/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0170 - val_loss: 0.1262\n",
            "Epoch 589/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0165 - val_loss: 0.1257\n",
            "Epoch 590/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0163 - val_loss: 0.1170\n",
            "Epoch 591/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0164 - val_loss: 0.1154\n",
            "Epoch 592/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0163 - val_loss: 0.1251\n",
            "Epoch 593/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0161 - val_loss: 0.1237\n",
            "Epoch 594/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0160 - val_loss: 0.1204\n",
            "Epoch 595/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0159 - val_loss: 0.1189\n",
            "Epoch 596/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0160 - val_loss: 0.1239\n",
            "Epoch 597/600\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.0157 - val_loss: 0.1226\n",
            "Epoch 598/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0157 - val_loss: 0.1171\n",
            "Epoch 599/600\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.0155 - val_loss: 0.1177\n",
            "Epoch 600/600\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.0153 - val_loss: 0.1219\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f55fb23cb50>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_loss = pd.DataFrame(model.history.history)"
      ],
      "metadata": {
        "id": "OoZPoBh0iT-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_loss.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "lV10zj55iUBF",
        "outputId": "f3fae3a8-9936-4901-ed53-2d27a28fe7ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f55fa928fa0>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yXfqXLUliUKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QEYG-CF8iUNr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}